<!--
# Remote Experiment Tracking with MLflow Tracking Server

* [https://mlflow.org/docs/latest/tracking/tutorials/remote-server.html](https://mlflow.org/docs/latest/tracking/tutorials/remote-server.html)

In this tutorial, you will learn how to set up MLflow Tracking environment for team development using the MLflow Tracking Server.

There are many benefits to utilize MLflow Tracking Server for remote experiment tracking:

* Collaboration: Multiple users can log runs to the same endpoint, and query runs and models logged by other users.
* Sharing Results: The tracking server also serves a Tracking UI endpoint, where team members can easily explore each other’s results.
* Centralized Access: The tracking server can be run as a proxy for the remote access for metadata and artifacts, making it easier to secure and audit access to data.
-->

# リモート実験トラッキングとMLflow Tracking サーバ

* [https://mlflow.org/docs/latest/tracking/tutorials/remote-server.html](https://mlflow.org/docs/latest/tracking/tutorials/remote-server.html)

このチュートリアルでは、MLflow Tracking サーバを使用してチーム開発用のMLflow Tracking 環境を設定する方法を学びます。

リモート実験トラッキング用のMLflow Tracking サーバを利用するメリットは多くあります：

* コラボレーション：複数のユーザーが同じエンドポイントに実行をログし、他のユーザーによってログされた実行やモデルを照会できます。
* 結果の共有：トラッキングサーバはトラッキングUIエンドポイントも提供し、チームメンバーがお互いの結果を簡単に探索できます。
* 集中化されたアクセス：トラッキングサーバはリモートアクセスのためのプロキシとして運用でき、データへのアクセスのセキュリティと監査を容易にします。

<!--
## How does it work?

The following picture depicts the architecture of using a remote MLflow Tracking Server with PostgreSQL and S3

![../../_images/scenario_5.png](https://mlflow.org/docs/latest/_images/scenario_5.png)
Artifacture diagram of MLflow Tracking Server with PostgreSQL and S3

Note

You can find the list of supported data stores in the artifact stores and backend stores <../backend-stores.html> documentation guides.

When you start logging runs to the MLflow Tracking Server, the following happens:

* Part 1a and b:
  * The MLflow client creates an instance of a RestStore and sends REST API requests to log MLflow entities
  * The Tracking Server creates an instance of an SQLAlchemyStore and connects to the remote host for inserting tracking information in the database (i.e., metrics, parameters, tags, etc.)
* Part 1c and d:
  *  Retrieval requests by the client return information from the configured SQLAlchemyStore table
* Part 2a and b:
  * Logging events for artifacts are made by the client using the HttpArtifactRepository to write files to MLflow Tracking Server
  * The Tracking Server then writes these files to the configured object store location with assumed role authentication
* Part 2c and d:
  * Retrieving artifacts from the configured backend store for a user request is done with the same authorized authentication that was configured at server start
  * Artifacts are passed to the end user through the Tracking Server through the interface of the HttpArtifactRepository
-->

## それはどのように機能するのか？

以下の画像は、PostgreSQLとS3を使用したリモートMLflow Tracking サーバのアーキテクチャを示しています。

![../../_images/scenario_5.png](https://mlflow.org/docs/latest/_images/scenario_5.png)
PostgreSQLとS3を使用したMLflow Tracking サーバのアーキテクチャ図

注意

サポートされているデータストアのリストは、アーティファクトストアとバックエンドストアのドキュメントガイド<../backend-stores.html>で見つけることができます。

MLflow Tracking サーバに実行をログし始めると、以下のことが起こります：

* パート1aおよびb：
  * MLflowクライアントはRestStoreのインスタンスを作成し、MLflowエンティティをログするためのREST APIリクエストを送信します。
  * トラッキングサーバはSQLAlchemyStoreのインスタンスを作成し、リモートホストに接続してデータベース（メトリクス、パラメータ、タグなど）に追跡情報を挿入します。
* パート1cおよびd：
  * クライアントによる検索リクエストは、設定されたSQLAlchemyStoreテーブルから情報を返します。
* パート2aおよびb：
  * アーティファクトのログイベントは、クライアントによってHttpArtifactRepositoryを使用してMLflow Tracking サーバにファイルを書き込むために行われます。
  * トラッキングサーバは、これらのファイルを設定されたオブジェクトストアの場所に、想定された役割認証で書き込みます。
* パート2cおよびd：
  * ユーザーリクエストに対して設定されたバックエンドストアからアーティファクトを取得するには、サーバ開始時に設定された同じ認証権限が使用されます。
  * アーティファクトは、HttpArtifactRepositoryのインターフェイスを通じてトラッキングサーバから最終ユーザーに渡されます。


<!--
## Getting Started

### Preface

In an actual production deployment environment, you will have multiple remote hosts to run both the tracking server and databases, as shown in the diagram above. However, for the purposes of this tutorial, we will just use a single machine with multiple Docker containers running on different ports, mimicking the remote environment with a far easier evaluation tutorial setup. We will also use MinIO, an S3-compatible object storage, as an artifact store so that you don’t need to have AWS account to run this tutorial.

### Step 1 - Get MLflow and additional dependencies

MLflow is available on PyPI. Also pyscopg2 and boto3 are required for accessing PostgreSQL and S3 with Python. If you don’t already have them installed on your system, you can install them with:
-->

## はじめに

### 序文

実際の本番展開環境では、上記の図に示されるように、トラッキングサーバとデータベースの両方を実行するための複数のリモートホストがあります。しかし、このチュートリアルの目的では、リモート環境を遥かに簡単に評価するチュートリアルセットアップで模倣するために、異なるポートで実行される複数のDockerコンテナを持つ単一のマシンを使用します。また、このチュートリアルを実行するためにAWSアカウントを必要としないように、アーティファクトストアとしてS3互換のオブジェクトストレージであるMinIOを使用します。

### ステップ1 - MLflowと追加の依存関係を入手

MLflowはPyPIで入手可能です。また、PythonでPostgreSQLとS3にアクセスするためにはpyscopg2とboto3が必要です。まだシステムにインストールされていない場合は、以下でインストールできます：

```Bash
pip install mlflow psycopg2 boto3
```

<!--
### Step 2 - Set up remote data stores

MLflow Tracking Server can interact with a variety of data stores to store experiment and run data as well as artifacts. In this tutorial, we will use Docker Compose to start two containers, each of them simulating remote servers in an actual environment.

1. PostgreSQL database as a backend store.
2. MinIO server as an artifact store.

#### Install docker and docker-compose

Note

These docker steps are only required for the tutorial purpose. MLflow itself doesn’t depend on Docker at all.

Follow the official instructions for installing Docker and Docker Compose. Then, run `docker --version` and `docker-compose --version` to make sure they are installed correctly.

#### Create compose.yaml

Create a file named `compose.yaml` with the following content:
-->

### ステップ2 - リモートデータストアの設定

MLflow Tracking サーバは、実験データや実行データ、アーティファクトを保存するためにさまざまなデータストアと対話できます。このチュートリアルでは、Docker Composeを使用して2つのコンテナを起動し、実際の環境でのリモートサーバをシミュレートします。

1. バックエンドストアとしてのPostgreSQLデータベース。
2. アーティファクトストアとしてのMinIOサーバ。

#### DockerとDocker Composeのインストール

注意

これらのDockerの手順はチュートリアルの目的のためだけに必要です。MLflow自体はDockerに依存していません。

DockerとDocker Composeの公式インストール手順に従ってください。その後、`docker --version` と `docker-compose --version` を実行して、正しくインストールされていることを確認してください。

#### compose.yamlを作成

次の内容で `compose.yaml` というファイルを作成します：

`compose.yaml`
```yaml
version: '3.7'
services:
  # PostgreSQL database
  postgres:
    image: postgres:latest
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: mlflowdb
    ports:
      - 5432:5432
    volumes:
      - ./postgres-data:/var/lib/postgresql/data
  # MinIO server
  minio:
    image: minio/minio
    expose:
      - "9000"
    ports:
      - "9000:9000"
      # MinIO Console is available at http://localhost:9001
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: "minio_user"
      MINIO_ROOT_PASSWORD: "minio_password"
    healthcheck:
      test: timeout 5s bash -c ':> /dev/tcp/127.0.0.1/9000' || exit 1
      interval: 1s
      timeout: 10s
      retries: 5
    command: server /data --console-address ":9001"
  # Create a bucket named "bucket" if it doesn't exist
  minio-create-bucket:
    image: minio/mc
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      bash -c "
      mc alias set minio http://minio:9000 minio_user minio_password &&
      if ! mc ls minio | grep --quiet bucket; then
        mc mb minio/bucket
      else
        echo 'bucket already exists'
      fi
      "
```

<!--
#### Start the containers

Run the following command from the same directory compose.yaml file resides to start the containers. This will start the containers for PostgreSQL and Minio server in the background, as well as create a new bucket named “bucket” in Minio.
-->

#### コンテナを起動

`compose.yaml` ファイルがある同じディレクトリから以下のコマンドを実行して、コンテナを起動します。これにより、PostgreSQLとMinioサーバのコンテナがバックグラウンドで起動され、Minioに「`bucket`」という名前の新しいバケットが作成されます。

```
docker compose up -d
```

<!--
### Step 3 - Start the Tracking Server

Note

In actual environment, you will have a remote host that will run the tracking server, but in this tutorial we will just use our local machine as a simulated surrogate for a remote machine.

#### Configure access

For the tracking server to access remote storage, it needs to be configured with the necessary credentials.
-->

### ステップ3 - トラッキングサーバを起動

注意

実際の環境では、トラッキングサーバを実行するリモートホストがありますが、このチュートリアルでは、リモートマシンの代理としてローカルマシンを使用します。

#### アクセスを設定

トラッキングサーバがリモートストレージにアクセスするためには、必要な認証情報を設定する必要があります。

```
export MLFLOW_S3_ENDPOINT_URL=http://localhost:9000 # Replace this with remote storage endpoint e.g. s3://my-bucket in real use cases
export AWS_ACCESS_KEY_ID=minio_user
export AWS_SECRET_ACCESS_KEY=minio_password
```

<!--
You can find the instructions for how to configure credentials for other storages in Supported Storage.

#### Launch the tracking server

To specify the backend store and artifact store, you can use the `--backend-store-uri` and `--artifacts-store-uri` options respectively.
-->

他のストレージの認証情報の設定方法については、サポートされるストレージで指示を見つけることができます。

#### トラッキングサーバを起動

バックエンドストアとアーティファクトストアを指定するには、それぞれ `--backend-store-uri` と `--artifacts-store-uri` オプションを使用します。

```
mlflow server \
  --backend-store-uri postgresql://user:password@localhost:5432/mlflowdb \
  --artifacts-destination s3://bucket \
  --host 0.0.0.0 \
  --port 5000
```

<!--
Replace `localhost` with the remote host name or IP address for your database server in actual environment.

### Step 4: Logging to the Tracking Server

Once the tracking server is running, you can log runs to it by setting the MLflow Tracking URI to the tracking server’s URI. Alternatively, you can use the `mlflow.set_tracking_uri()` API to set the tracking URI.
-->

実際の環境では、`localhost` をデータベースサーバのリモートホスト名またはIPアドレスに置き換えてください。

### ステップ4: トラッキングサーバにログを記録

トラッキングサーバが稼働していれば、トラッキングサーバのURIをMLflow Tracking URIに設定することにより、そこに実行をログすることができます。あるいは、`mlflow.set_tracking_uri()` APIを使用してトラッキングURIを設定することもできます。

その後、通常どおりMLflow Tracking APIを使用してコードを実行します。以下のコードは、diabetesデータセットでscikit-learnのRandomForestモデルの学習を実行します：

```
export MLFLOW_TRACKING_URI=http://127.0.0.1:5000  # Replace with remote host name or IP address in an actual environment
```

<!--
Then run your code with MLflow tracking APIs as usual. The following code runs training for a scikit-learn RandomForest model on the diabetes dataset:
-->

その後、通常どおりMLflow Tracking APIを使用してコードを実行します。以下のコードは、diabetesデータセットでscikit-learnのRandomForestモデルの学習を実行します：

```Python
import mlflow

from sklearn.model_selection import train_test_split
from sklearn.datasets import load_diabetes
from sklearn.ensemble import RandomForestRegressor

mlflow.autolog()

db = load_diabetes()
X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)

# Create and train models.
rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)
rf.fit(X_train, y_train)

# Use the model to make predictions on the test dataset.
predictions = rf.predict(X_test)
```

<!--
### Step 5: View logged Run in Tracking UI

Our pseudo-remote MLflow Tracking Server also hosts the Tracking UI on the same endpoint. In an actual deployment environment with a remote tracking server, this is also the case. You can access the UI by navigating to `http://127.0.0.1:5000` (replace with remote host name or IP address in actual environment) in your browser.
-->

### ステップ5: トラッキングUIでログされた実行を表示

私たちの仮想リモートMLflow Tracking サーバは、同じエンドポイントでトラッキングUIもホストしています。実際のデプロイ環境でのリモートトラッキングサーバでもこれが当てはまります。ブラウザで `http://127.0.0.1:5000` にアクセスすることによりUIにアクセスできます（実際の環境ではリモートホスト名またはIPアドレスに置き換えてください）。

<!--
### Step 6: Download artifacts

MLflow Tracking Server also serves as a proxy host for artifact access. Artifact access is enabled through the proxy URIs such as `runs:/`, `mlflow-artifacts:/`, giving users access to this location without having to manage credentials or permissions of direct access.
-->

### ステップ6: アーティファクトのダウンロード

MLflow Tracking サーバはまた、アーティファクトアクセスのためのプロキシホストとしても機能します。アーティファクトアクセスは `runs:/` や `mlflow-artifacts:/` といったプロキシURIを通じて有効にされ、ユーザーは直接アクセスの認証情報や権限を管理することなくこの場所にアクセスできます。

```Python
import mlflow

run_id = "YOUR_RUN_ID"  # You can find run ID in the Tracking UI
artifact_path = "model"

# Download artifact via the tracking server
mlflow_artifact_uri = f"runs://{run_id}/{artifact_path}"
local_path = mlflow.artifacts.download_artifacts(mlflow_artifact_uri)

# Load the model
model = mlflow.sklearn.load_model(local_path)
```

<!--
## What’s Next?

Now you have learned how to set up MLflow Tracking Server for remote experiment tracking! There are a couple of more advanced topics you can explore:

* Other configurations for the Tracking Server: By default, MLflow Tracking Server serves both backend store and artifact store. You can also configure the Tracking Server to serve only backend store or artifact store, to handle different use cases such as large traffic or security concerns. See other use cases for how to customize the Tracking Server for these use cases.
* Secure the Tracking Server: The --host option exposes the service on all interfaces. If running a server in production, we would recommend not exposing the built-in server broadly (as it is unauthenticated and unencrypted). Read Secure Tracking Server for the best practices to secure the Tracking Server in production.
* New Features: The MLflow team and a host of community contributors constantly develops new features to support broader use cases. See New Features to catch up with the latest features!
-->


## 次は何を？

これで、リモート実験トラッキングのためのMLflow Tracking サーバの設定方法を学びました！さらに高度なトピックを探求することができます：

* トラッキングサーバのその他の設定：デフォルトでは、MLflow Tracking サーバはバックエンドストアとアーティファクトストアの両方を提供します。また、トラッキングサーバをバックエンドストアのみ、またはアーティファクトストアのみを提供するように設定することもでき、大量のトラフィックやセキュリティの懸念などの異なるユースケースに対応することができます。これらのユースケースにトラッキングサーバをカスタマイズする方法については、他のユースケースを参照してください。
* トラッキングサーバをセキュアにする：`--host` オプションはサービスをすべてのインターフェースで公開します。本番環境でサーバを実行する場合は、組み込みサーバを広く公開することは推奨されません（認証されておらず、暗号化されていないため）。本番環境でトラッキングサーバを安全にするためのベストプラクティスについては、セキュアトラッキングサーバを読んでください。
* 新機能：MLflowチームおよび多くのコミュニティ貢献者は、より幅広いユースケースをサポートするために常に新機能を開発しています。最新の機能に追いつくために新機能を参照してください！

