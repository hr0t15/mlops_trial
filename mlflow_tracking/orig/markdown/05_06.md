<!--
# Artifact Stores

* [https://mlflow.org/docs/latest/tracking/artifacts-stores.html](https://mlflow.org/docs/latest/tracking/artifacts-stores.html)

The artifact store is a core component in MLflow Tracking where MLflow stores (typicaly large) arifacts for each run such as model weights (e.g. a pickled scikit-learn model), images (e.g. PNGs), model and data files (e.g. Parquet file). Note that metadata like parameters, metrics, and tags are stored in a backend store (e.g., PostGres, MySQL, or MSSQL Database), the other component of the MLflow Tracking.
-->
# アーティファクトストア

* [https://mlflow.org/docs/latest/tracking/artifacts-stores.html](https://mlflow.org/docs/latest/tracking/artifacts-stores.html)

アーティファクトストアはMLflow Tracking の核となるコンポーネントで、各実行に関連する（通常は大きな）アーティファクト、例えばモデルの重み（例：ピクルス化されたscikit-learnモデル）、画像（例：PNG）、モデルとデータファイル（例：Parquetファイル）を保存します。パラメータ、メトリクス、タグなどのメタデータはバックエンドストア（例：PostGres、MySQL、MSSQLデータベース）に保存され、これはMLflow Tracking のもう一つのコンポーネントです。

<!--
## Configuring an Artifact Store

MLflow by default stores artifacts in local `./mlruns` directory, but also supports various locations suitable for large data: Amazon S3, Azure Blob Storage, Google Cloud Storage, SFTP server, and NFS. You can connect those remote storages via the MLflow Tracking server. See tracking server setup and the specific section for your storage in supported storages for guidance on how to connect to your remote storage of choice.
-->

## アーティファクトストアの設定

MLflowはデフォルトでアーティファクトをローカルの`./mlruns`ディレクトリに保存しますが、Amazon S3、Azure Blob Storage、Google Cloud Storage、SFTPサーバ、NFSなど、大容量データに適したさまざまな場所もサポートしています。これらのリモートストレージはMLflow Tracking サーバ経由で接続できます。トラッキングサーバの設定と、選択したストレージのサポートされているストレージの特定のセクションを参照して、リモートストレージに接続する方法についてのガイダンスを参照してください。


<!--
### Managing Artifact Store Access

To allow the server and clients to access the artifact location, you should configure your cloud provider credentials as you would for accessing them in any other capacity. For example, for S3, you can set the `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` environment variables, use an IAM role, or configure a default profile in `~/.aws/credentials`.

Important

Access credentials and configuration for the artifact storage location are configured once during server initialization in the place of having users handle access credentials for artifact-based operations. Note that all users who have access to the Tracking Server in this mode will have access to artifacts served through this assumed role.
-->
### アーティファクトストアアクセスの管理

サーバとクライアントがアーティファクトの場所にアクセスできるようにするには、他の用途でアクセスする場合と同様に、クラウドプロバイダーの認証情報を設定する必要があります。たとえば、S3の場合は、`AWS_ACCESS_KEY_ID` と `AWS_SECRET_ACCESS_KEY` 環境変数を設定するか、IAMロールを使用するか、`~/.aws/credentials` にデフォルトプロファイルを設定します。

重要

アーティファクトストレージの場所のアクセス認証情報と設定は、サーバの初期化中に一度設定され、ユーザーがアーティファクトに基づく操作のアクセス認証情報を扱う必要がなくなります。このモードでトラッキングサーバにアクセスできるすべてのユーザーは、この想定された役割を通じて提供されるアーティファクトにアクセスできることになります。


<!--
### Setting an access Timeout
You can set an environment variable MLFLOW_ARTIFACT_UPLOAD_DOWNLOAD_TIMEOUT (in seconds) to configure the timeout for artifact uploads and downloads. If it’s not set, MLflow will use the default timeout for the underlying storage client library (e.g. boto3 for S3). Note that this is experimental feature, may be changed or removed.
-->

### アクセスタイムアウトの設定

環境変数 `MLFLOW_ARTIFACT_UPLOAD_DOWNLOAD_TIMEOUT`（秒単位）を設定して、アーティファクトのアップロードとダウンロードのタイムアウトを設定できます。設定されていない場合、MLflowは基盤となるストレージクライアントライブラリのデフォルトタイムアウト（例：S3の場合はboto3）を使用します。これは実験的な機能であり、変更または削除される可能性があります。


<!--
### Setting a Default Artifact Location for Logging

MLflow automatically records the artifact_uri property as a part of `mlflow.entities.RunInfo`, so you can retrieve the location of the artifacts for historical runs using the `mlflow.get_artifact_uri()` API. Also, artifact_location is a property recorded on `mlflow.entities.Experiment` for setting the default location to store artifacts for all runs in a given experiment.

Important

If you do not specify a `--default-artifact-root` or an artifact URI when creating the experiment (for example, `mlflow experiments create --artifact-location s3://<my-bucket>`), the artifact root will be set as a path inside the local file store (the hard drive of the computer executing your run). Typically this is not an appropriate location, as the client and server probably refer to different physical locations (that is, the same path on different disks).
-->

### ログ記録のデフォルトアーティファクト位置の設定

MLflowは `mlflow.entities.RunInfo` の一部として `artifact_uri` プロパティを自動的に記録するため、`mlflow.get_artifact_uri()` APIを使用して過去の実行のアーティファクトの場所を取得できます。また、`artifact_location` は `mlflow.entities.Experiment` に記録されたプロパティで、特定の実験のすべての実行のアーティファクトを保存するデフォルトの場所を設定するために使用されます。

重要

実験を作成する際（例：`mlflow experiments create --artifact-location s3://<my-bucket>`）に `--default-artifact-root` やアーティファクトURIを指定しない場合、アーティファクトのルートはローカルファイルストア内のパス（実行を実行しているコンピュータのハードドライブ）として設定されます。通常、これは適切な場所ではありません。クライアントとサーバはおそらく異なる物理的な場所を参照しているためです（つまり、異なるディスク上の同じパス）。

<!--
## Supported storage types for the Artifact Store

### Amazon S3 and S3-compatible storage

To store artifacts in S3 (whether on Amazon S3 or on an S3-compatible alternative, such as MinIO or Digital Ocean Spaces), specify a URI of the form `s3://<bucket>/<path>`. MLflow obtains credentials to access S3 from your machine’s IAM role, a profile in `~/.aws/credentials`, or the environment variables `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` depending on which of these are available. For more information on how to set credentials, see Set up AWS Credentials and Region for Development.

Followings are commonly used environment variables for configuring S3 storage access. The complete list of configurable parameters for an S3 client is available in the boto3 documentation.

### Passsing Extra Arguments to S3 Upload

To add S3 file upload extra arguments, set `MLFLOW_S3_UPLOAD_EXTRA_ARGS` to a JSON object of key/value pairs. For example, if you want to upload to a KMS Encrypted bucket using the KMS Key 1234:
-->

## アーティファクトストアのサポートされるストレージタイプ

### Amazon S3およびS3互換ストレージ

S3（Amazon S3またはMinIOやDigital Ocean SpacesのようなS3互換の代替品であるかどうかにかかわらず）にアーティファクトを保存するには、`s3://<bucket>/<path>` の形式のURIを指定します。MLflowは、使用可能な場合に、マシンのIAMロール、`~/.aws/credentials` のプロファイル、または `AWS_ACCESS_KEY_ID` と `AWS_SECRET_ACCESS_KEY` の環境変数からS3へのアクセスのための認証情報を取得します。認証情報の設定方法の詳細については、AWS CredentialsとRegionの設定を参照してください。

以下は、S3ストレージアクセスを設定するために一般的に使用される環境変数です。S3クライアントに対して設定可能なパラメータの完全なリストは、boto3ドキュメントで利用可能です。

### S3アップロードへの追加引数の渡し

S3ファイルアップロードの追加引数を追加するには、`MLFLOW_S3_UPLOAD_EXTRA_ARGS`をキー/値ペアのJSONオブジェクトに設定します。たとえば、KMS Key 1234を使用してKMS暗号化バケットにアップロードする場合は、次のようにします：


```bash
export MLFLOW_S3_UPLOAD_EXTRA_ARGS='{"ServerSideEncryption": "aws:kms", "SSEKMSKeyId": "1234"}'
```

<!--
For a list of available extra args see Boto3 ExtraArgs Documentation.

### Setting Custom S3 Endpoint

To store artifacts in a custom endpoint, set the `MLFLOW_S3_ENDPOINT_URL` to your endpoint’s URL. For example, if you are using Digital Ocean Spaces:
-->

利用可能な追加引数のリストについては、Boto3 ExtraArgs Documentationを参照してください。

### カスタムS3エンドポイントの設定

アーティファクトをカスタムエンドポイントに保存するには、`MLFLOW_S3_ENDPOINT_URL`をエンドポイントのURLに設定します。例えば、Digital Ocean Spacesを使用している場合は次のようにします：


```bash
export MLFLOW_S3_ENDPOINT_URL=https://<region>.digitaloceanspaces.com
```

<!--
If you have a MinIO server at 1.2.3.4 on port 9000:
-->

MinIOサーバが`1.2.3.4`の`9000`ポートで稼働している場合：

```bash
export MLFLOW_S3_ENDPOINT_URL=http://1.2.3.4:9000
```

<!--
### Using Non-TLS Authentication

If the MinIO server is configured with using SSL self-signed or signed using some internal-only CA certificate, you could set `MLFLOW_S3_IGNORE_TLS` or `AWS_CA_BUNDLE` variables (not both at the same time!) to disable certificate signature check, or add a custom CA bundle to perform this check, respectively:
-->

### 非TLS認証の使用

MinIOサーバがSSL自己署名または内部専用のCA証明書を使用して構成されている場合、証明書の署名チェックを無効にするために `MLFLOW_S3_IGNORE_TLS` または `AWS_CA_BUNDLE` 変数（同時に両方は設定しないでください！）を設定するか、それぞれカスタムCAバンドルを追加してこのチェックを実行できます：


```bash
export MLFLOW_S3_IGNORE_TLS=true
#or
export AWS_CA_BUNDLE=/some/ca/bundle.pem
```

<!--
### Setting Bucket Region

Additionally, if MinIO server is configured with non-default region, you should set `AWS_DEFAULT_REGION` variable:
-->


### バケットリージョンの設定

さらに、MinIOサーバがデフォルト以外のリージョンで構成されている場合は、`AWS_DEFAULT_REGION`変数を設定する必要があります：


```bash
export AWS_DEFAULT_REGION=my_region
```

<!--
Warning

The MLflow tracking server utilizes specific reserved keywords to generate a qualified path. These environment configurations, if present in the client environment, can create path resolution issues. For example, providing `--default-artifact-root $MLFLOW_S3_ENDPOINT_URL` on the server side and `MLFLOW_S3_ENDPOINT_URL` on the client side will create a client path resolution issue for the artifact storage location. Upon resolving the artifact storage location, the MLflow client will use the value provided by `--default-artifact-root` and suffixes the location with the values provided in the environment variable `MLFLOW_S3_ENDPOINT_URL`. Depending on the value set for the environment variable `MLFLOW_S3_ENDPOINT_URL`, the resulting artifact storage path for this scenario would be one of the following invalid object store paths: `https://<bucketname>.s3.<region>.amazonaws.com/<key>/<bucketname>/<key>` or `s3://<bucketname>/<key>/<bucketname>/<key>`. To prevent path parsing issues, ensure that reserved environment variables are removed (``unset``) from client environments.
-->

警告

MLflow Tracking サーバは、特定の予約済みキーワードを使用して資格のあるパスを生成します。クライアント環境にこれらの環境設定が存在する場合、パス解決の問題を引き起こす可能性があります。例えば、サーバ側で `--default-artifact-root $MLFLOW_S3_ENDPOINT_URL` を提供し、クライアント側で `MLFLOW_S3_ENDPOINT_URL` を設定すると、アーティファクトストレージの場所のクライアントパス解決問題が発生します。アーティファクトストレージの場所を解決すると、MLflowクライアントは `--default-artifact-root` で提供された値を使用し、環境変数 `MLFLOW_S3_ENDPOINT_URL` で提供された値で場所を後置します。環境変数 `MLFLOW_S3_ENDPOINT_URL` に設定された値によって、このシナリオでの結果としてのアーティファクトストレージパスは次の無効なオブジェクトストアパスのいずれかになります：`https://<bucketname>.s3.<region>.amazonaws.com/<key>/<bucketname>/<key>` または `s3://<bucketname>/<key>/<bucketname>/<key>`。パス解析の問題を防ぐために、クライアント環境から予約環境変数を削除する（`unset`）ことを確認してください。



## ---- いったん対象外 ----

### Azure Blob Storage

To store artifacts in Azure Blob Storage, specify a URI of the form `wasbs://<container>@<storage-account>.blob.core.windows.net/<path>`. MLflow expects that your Azure Storage access credentials are located in the `AZURE_STORAGE_CONNECTION_STRING` and `AZURE_STORAGE_ACCESS_KEY` environment variables or having your credentials configured such that the `DefaultAzureCredential()`. class can pick them up. The order of precedence is:

1. `AZURE_STORAGE_CONNECTION_STRING`
2. `AZURE_STORAGE_ACCESS_KEY`
3. `DefaultAzureCredential()`

You must set one of these options on both your client application and your MLflow tracking server. Also, you must run pip install azure-storage-blob separately (on both your client and the server) to access Azure Blob Storage. Finally, if you want to use DefaultAzureCredential, you must pip install azure-identity; MLflow does not declare a dependency on these packages by default.

You may set an MLflow environment variable to configure the timeout for artifact uploads and downloads:

* `MLFLOW_ARTIFACT_UPLOAD_DOWNLOAD_TIMEOUT` - (Experimental, may be changed or removed) Sets the timeout for artifact upload/download in seconds (Default: 600 for Azure blob).

### Google Cloud Storage

To store artifacts in Google Cloud Storage, specify a URI of the form `gs://<bucket>/<path>`. You should configure credentials for accessing the GCS container on the client and server as described in the GCS documentation. Finally, you must run `pip install google-cloud-storage` (on both your client and the server) to access Google Cloud Storage; MLflow does not declare a dependency on this package by default.

You may set some MLflow environment variables to troubleshoot GCS read-timeouts (eg. due to slow transfer speeds) using the following variables:

* `MLFLOW_ARTIFACT_UPLOAD_DOWNLOAD_TIMEOUT` - (Experimental, may be changed or removed) Sets the standard timeout for transfer operations in seconds (Default: 60 for GCS). Use -1 for indefinite timeout.
* `MLFLOW_GCS_DEFAULT_TIMEOUT` - (Deprecated, please use `MLFLOW_ARTIFACT_UPLOAD_DOWNLOAD_TIMEOUT`) Sets the standard timeout for transfer operations in seconds (Default: 60). Use -1 for indefinite timeout.
* `MLFLOW_GCS_UPLOAD_CHUNK_SIZE` - Sets the standard upload chunk size for bigger files in bytes (Default: 104857600 ≙ 100MiB), must be multiple of 256 KB.
* `MLFLOW_GCS_DOWNLOAD_CHUNK_SIZE` - Sets the standard download chunk size for bigger files in bytes (Default: 104857600 ≙ 100MiB), must be multiple of 256 KB


### FTP server

To store artifacts in a FTP server, specify a URI of the form `ftp://user@host/path/to/directory`. The URI may optionally include a password for logging into the server, e.g. `ftp://user:pass@host/path/to/directory`


### SFTP Server

To store artifacts in an SFTP server, specify a URI of the form `sftp://user@host/path/to/directory`. You should configure the client to be able to log in to the SFTP server without a password over SSH (e.g. public key, identity file in ssh_config, etc.).

The format `sftp://user:pass@host/` is supported for logging in. However, for safety reasons this is not recommended.

When using this store, `pysftp` must be installed on both the server and the client. Run `pip install pysftp` to install the required package.


### NFS

To store artifacts in an NFS mount, specify a URI as a normal file system path, e.g., `/mnt/nfs`. This path must be the same on both the server and the client – you may need to use symlinks or remount the client in order to enforce this property.


### HDFS

To store artifacts in HDFS, specify a `hdfs:` URI. It can contain host and port: `hdfs://<host>:<port>/<path>` or just the path: `hdfs://<path>`.

There are also two ways to authenticate to HDFS:

* Use current UNIX account authorization
* Kerberos credentials using the following environment variables:

```
export MLFLOW_KERBEROS_TICKET_CACHE=/tmp/krb5cc_22222222
export MLFLOW_KERBEROS_USER=user_name_to_use
```

Most of the cluster contest settings are read from `hdfs-site.xml` accessed by the HDFS native driver using the `CLASSPATH` environment variable.

The HDFS driver that is used is `libhdfs`.


## Deletion Behavior

In order to allow MLflow Runs to be restored, Run metadata and artifacts are not automatically removed from the backend store or artifact store when a Run is deleted. The `mlflow gc` CLI is provided for permanently removing Run metadata and artifacts for deleted runs.
