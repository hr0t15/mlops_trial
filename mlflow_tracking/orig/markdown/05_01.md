<!--
# MLflow Tracking

* [https://mlflow.org/docs/latest/tracking.html](https://mlflow.org/docs/latest/tracking.html)

The MLflow Tracking is an API and UI for logging parameters, code versions, metrics, and output files when running your machine learning code and for later visualizing the results. MLflow Tracking provides Python, REST, R, and Java APIs.

![_images/tracking-metrics-ui-temp.png](https://mlflow.org/docs/latest/_images/tracking-metrics-ui-temp.png)

A screenshot of the MLflow Tracking UI, showing a plot of validation loss metrics during model training.
-->

# MLflow トラッキング

* [https://mlflow.org/docs/latest/tracking.html](https://mlflow.org/docs/latest/tracking.html)

MLflow Tracking は、機械学習コードを実行する際にパラメータ、コードバージョン、メトリクス、出力ファイルをログに記録し、後で結果を可視化するためのAPIおよびUIです。MLflow Tracking はPython、REST、R、JavaのAPIを提供しています。

![_images/tracking-metrics-ui-temp.png](https://mlflow.org/docs/latest/_images/tracking-metrics-ui-temp.png)

MLflow Tracking UIのスクリーンショットで、モデル学習中の検証損失メトリクスのプロットを表示しています。

<!--
## Quickstart

If you haven’t used MLflow Tracking before, we strongly recommend going through the following quickstart tutorial.

[MLflow Tracking Quickstart](https://mlflow.org/docs/latest/getting-started/intro-quickstart/index.html)

A great place to start to learn the fundamentals of MLflow Tracking! Learn in 5 minutes how to log, register, and load a model for inference.
-->


## クイックスタート

もしMLflow Tracking を使ったことがないなら、以下のクイックスタートチュートリアルを通じて学ぶことを強くお勧めします。

[MLflow トラッキングクイックスタート](https://mlflow.org/docs/latest/getting-started/intro-quickstart/index.html)

MLflow トラッキングの基本を学ぶのに最適な場所！5分でログ記録、登録、推論用のモデルのロードの方法を学びます。


<!--
## Concepts

### Runs

MLflow Tracking is organized around the concept of runs, which are executions of some piece of data science code, for example, a single `python train.py` execution. Each run records metadata (various information about your run such as metrics, parameters, start and end times) and artifacts (output files from the run such as model weights, images, etc).

### Experiments

An experiment groups together runs for a specific task. You can create an experiment using the CLI, API, or UI. The MLflow API and UI also let you create and search for experiments. See [Organizing Runs into Experiments](https://mlflow.org/docs/latest/tracking/tracking-api.html#organizing-runs-in-experiments) for more details on how to organize your runs into experiments.

### Tracking Runs

[MLflow Tracking APIs](https://mlflow.org/docs/latest/tracking/tracking-api.html) provide a set of functions to track your runs. For example, you can call [`mlflow.start_run()`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.start_run) to start a new run, then call [Logging Functions](https://mlflow.org/docs/latest/tracking/tracking-api.html#tracking-logging-functions) such as [`mlflow.log_param()`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_param) and [`mlflow.log_metric()`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_metric) to log a parameters and metrics respectively. Please visit the [Tracking API documentation](https://mlflow.org/docs/latest/tracking/tracking-api.html) for more details about using these APIs.
-->

## コンセプト

### 実行

MLflow Tracking は「実行」のコンセプトを中心に構築されています。実行は、たとえば単一の`python train.py`の実行など、あるデータサイエンスコードの実行です。各実行はメタデータ（実行に関するさまざまな情報、例えばメトリクス、パラメータ、開始と終了の時間）とアーティファクト（実行からの出力ファイル、例えばモデルの重み、画像など）を記録します。

### 実験

実験は特定のタスクのために実行をまとめたものです。CLI、API、またはUIを使用して実験を作成できます。MLflow APIとUIでは、実験の作成や検索も行えます。実行を実験にまとめる方法の詳細については、[実行を実験に整理する](https://mlflow.org/docs/latest/tracking/tracking-api.html#organizing-runs-in-experiments)をご覧ください。

### 実行の追跡

[MLflow Tracking API](https://mlflow.org/docs/latest/tracking/tracking-api.html)は、実行を追跡するための一連の機能を提供します。例えば、[`mlflow.start_run()`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.start_run)を呼び出して新しい実行を開始し、[`mlflow.log_param()`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_param)や[`mlflow.log_metric()`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_metric)などの[ログ記録機能](https://mlflow.org/docs/latest/tracking/tracking-api.html#tracking-logging-functions)を呼び出してパラメータやメトリクスをログに記録します。これらのAPIの使用方法の詳細については、[トラッキングAPIドキュメント](https://mlflow.org/docs/latest/tracking/tracking-api.html)をご覧ください。

```python
import mlflow

with mlflow.start_run():
    mlflow.log_param("lr", 0.001)
    # Your ml code
    ...
    mlflow.log_metric("val_loss", val_loss)
```

<!--
Alternatively, [Auto-logging](https://mlflow.org/docs/latest/tracking/autolog.html) offers the ultra-quick setup for starting MLflow tracking. This powerful feature allows you to log metrics, parameters, and models without the need for explicit log statements - all you need to do is call [`mlflow.autolog()`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.autolog) before your training code. Auto-logging supports popular libraries such as Scikit-learn, XGBoost, PyTorch, Keras, Spark, and more. See [Automatic Logging Documentation](https://mlflow.org/docs/latest/tracking/autolog.html#automatic-logging) for supported libraries and how to use auto-logging APIs with each of them.
-->

また、[オートロギング](https://mlflow.org/docs/latest/tracking/autolog.html)は、MLflow Tracking を始めるための超速設定を提供します。この強力な機能を使用すると、明示的なログステートメントなしでメトリクス、パラメータ、およびモデルをログできます。学習コードの前に[`mlflow.autolog()`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.autolog)を呼び出すだけです。オートロギングはScikit-learn、XGBoost、PyTorch、Keras、Sparkなどの人気ライブラリをサポートしています。サポートされているライブラリとそれぞれのAPIを使用する方法については、[自動ログ記録ドキュメント](https://mlflow.org/docs/latest/tracking/autolog.html#automatic-logging)を参照してください。


```python
import mlflow

mlflow.autolog()

# Your training code...
```

<!--
Note

By default, without any particular server/database configuration, MLflow Tracking logs data to the local mlruns directory. If you want to log your runs to a different location, such as a remote database and cloud storage, to share your results with your team, follow the instructions in the Set up MLflow Tracking Environment section.


## Tracking Datasets

MLflow offers the ability to track datasets that are associated with model training events. These metadata associated with the Dataset can be stored through the use of the [`mlflow.log_input()`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_input) API. To learn more, please visit the [MLflow data documentation](https://mlflow.org/docs/latest/tracking/data-api.html) to see the features available in this API.
-->

注記

特にサーバ/データベースの設定を行わない場合、MLflow Tracking はデータをローカルのmlrunsディレクトリにログします。実行を別の場所（例えばリモートデータベースやクラウドストレージ）にログし、結果をチームと共有したい場合は、「MLflow Tracking 環境の設定」セクションの指示に従ってください。

## データセットのトラッキング

MLflowは、モデル学習イベントに関連付けられたデータセットをトラッキングする機能を提供します。データセットに関連付けられたメタデータは、[`mlflow.log_input()`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_input) APIを使用して保存できます。詳細については、[MLflowデータドキュメント](https://mlflow.org/docs/latest/tracking/data-api.html)を参照して、このAPIで利用可能な機能を確認してください。

<!--

## Explore Runs and Results

### Tracking UI

The Tracking UI lets you visually explore your experiments and runs, as shown on top of this page.

* Experiment-based run listing and comparison (including run comparison across multiple experiments)
* Searching for runs by parameter or metric value
* Visualizing run metrics
* Downloading run results (artifacts and metadata)

If you log runs to a local `mlruns` directory, run the following command in the directory above it, then access [http://127.0.0.1:5000](http://127.0.0.1:5000) in your browser.
-->

## 実行と結果の探索

### トラッキングUI

トラッキングUIを使用すると、このページの上部に示されているように、実験と実行を視覚的に探索できます。

* 実験ベースの実行リストと比較（複数の実験間での実行比較を含む）
* パラメーターやメトリック値による実行の検索
* 実行メトリックの可視化
* 実行結果のダウンロード（アーティファクトとメタデータ）

ローカルの`mlruns`ディレクトリに実行をログする場合は、そのディレクトリの上のディレクトリで以下のコマンドを実行し、ブラウザで[http://127.0.0.1:5000](http://127.0.0.1:5000)にアクセスします。


```bash
mlflow ui --port 5000
```

<!--
Alternatively, the [MLflow Tracking Server](https://mlflow.org/docs/latest/tracking.html#tracking-server) serves the same UI and enables remote storage of run artifacts. In that case, you can view the UI at `http://<IP address of your MLflow tracking server>:5000` from any machine that can connect to your tracking server.
-->

また、[MLflow Tracking サーバ](https://mlflow.org/docs/latest/tracking.html#tracking-server)も同じUIを提供し、実行アーティファクトのリモート保存を可能にします。その場合、トラッキングサーバに接続できる任意のマシンから`http://<あなたのMLflow Tracking サーバのIPアドレス>:5000`でUIを閲覧できます。


<!--
### Querying Runs Programmatically

You can also access all of the functions in the Tracking UI programmatically with MlflowClient.

For example, the following code snippet search for runs that has the best validation loss among all runs in the experiment.
-->

### プログラムで実行をクエリする

MlflowClientを使用して、トラッキングUIのすべての機能にプログラムでアクセスすることもできます。

例えば、以下のコードスニペットは実験中のすべての実行の中で最良の検証損失を持つ実行を検索します。


```python
client = mlflow.tracking.MlflowClient()
experiment_id = "0"
best_run = client.search_runs(
    experiment_id, order_by=["metrics.val_loss ASC"], max_results=1
)[0]
print(best_run.info)
# {'run_id': '...', 'metrics': {'val_loss': 0.123}, ...}
```

<!--
### Set up the MLflow Tracking Environment

Note

If you just want to log your experiment data and models to local files, you can skip this section.

MLflow Tracking supports many different scenarios for your development workflow. This section will guide you through how to set up the MLflow Tracking environment for your particular use case. From a bird’s-eye view, the MLflow Tracking environment consists of the following components.
-->

### MLflow Tracking 環境の設定

注記

実験データやモデルをローカルファイルにログするだけの場合は、このセクションをスキップしても構いません。

MLflow Tracking は、開発ワークフローのさまざまなシナリオをサポートします。このセクションでは、特定の使用例に合わせてMLflow Tracking 環境を設定する方法を案内します。鳥瞰図から見ると、MLflow Tracking 環境は以下のコンポーネントで構成されています。

<!--
## Components

### MLflow Tracking APIs

You can call MLflow Tracking APIs in your ML code to log runs and communicate with the MLflow Tracking Server if necessary.

### Backend Store

The backend store persists various metadata for each Run, such as run ID, start and end times, parameters, metrics, etc. MLflow supports two types of storage for the backend: file-system-based like local files and database-based like PostgreSQL.

### Artifact Store

Artifact store persists (typicaly large) arifacts for each run, such as model weights (e.g. a pickled scikit-learn model), images (e.g. PNGs), model and data files (e.g. Parquet file). MLflow stores artifacts ina a local file (mlruns) by default, but also supports different storage options such as Amazon S3 and Azure Blob Storage.

### MLflow Tracking Server (Optional)

MLflow Tracking Server is a stand-alone HTTP server that provides REST APIs for accessing backend and/or artifact store. Tracking server also offers flexibility to configure what data to server, govern access control, versioning, and etc. Read MLflow Tracking Server documentation for more details.

### Common Setups

By configuring these components properly, you can create an MLflow Tracking environment suitable for your team’s development workflow. The following diagram and table show a few common setups for the MLflow Tracking environment.

![_images/tracking-setup-overview.png](https://mlflow.org/docs/latest/_images/tracking-setup-overview.png)

1. Localhost (default)
2. Local Tracking with Local Database
3. Remote Tracking with MLflow Tracking Server
-->


## コンポーネント

### MLflow Tracking API

MLコード内でMLflow Tracking APIを呼び出して実行をログし、必要に応じてMLflow Tracking サーバと通信できます。

### バックエンドストア

バックエンドストアは、各実行の様々なメタデータ（実行ID、開始および終了時間、パラメータ、メトリクスなど）を永続化します。MLflowは、ファイルシステムベース（ローカルファイルなど）とデータベースベース（PostgreSQLなど）の2種類のストレージをサポートしています。

### アーティファクトストア

アーティファクトストアは、各実行のアーティファクト（通常は大きい）を永続化します。例えば、モデルの重み（ピクルス化されたscikit-learnモデルなど）、画像（PNGファイルなど）、モデルおよびデータファイル（Parquetファイルなど）がこれに該当します。MLflowはデフォルトでアーティファクトをローカルファイル（mlruns）に保存しますが、Amazon S3やAzure Blob Storageなどの異なるストレージオプションもサポートしています。

### MLflow Tracking サーバ（オプション）

MLflow Tracking サーバは、バックエンドおよび/またはアーティファクトストアにアクセスするためのREST APIを提供するスタンドアロンのHTTPサーバです。トラッキングサーバは、どのデータをサーバにするか、アクセス制御、バージョニングなどを設定する柔軟性を提供します。詳細はMLflow Tracking サーバドキュメントをご覧ください。

### 一般的なセットアップ

これらのコンポーネントを適切に設定することで、チームの開発ワークフローに適したMLflow Tracking 環境を作成できます。以下の図と表は、MLflow Tracking 環境の一般的なセットアップをいくつか示しています。

![_images/tracking-setup-overview.png](https://mlflow.org/docs/latest/_images/tracking-setup-overview.png)

1. ローカルホスト（デフォルト）
2. ローカルトラッキングとローカルデータベース
3. MLflow Tracking サーバを使ったリモートトラッキング

<!--
Scenario

Solo development

Solo development

Team development

Use Case

By default, MLflow records metadata and artifacts for each run to a local directory, mlruns. This is the simplest way to get started with MLflow Tracking, without setting up any external server, database, and storage.

The MLflow client can interface with a SQLAlchemy-compatible database (e.g., SQLite, PostgreSQL, MySQL) for the backend. Saving metadata to a database allows you cleaner management of your experiment data while skipping the effort of setting up a server.

MLflow Tracking Server can be configured with an artifacts HTTP proxy, passing artifact requests through the tracking server to store and retrieve artifacts without having to interact with underlying object store services. This is particularly useful for team development scenarios where you want to store artifacts and experiment metadata in a shared location with proper access control.

Tutorial

QuickStart

Tracking Experiments using a Local Database

Remote Experiment Tracking with MLflow Tracking Server
-->

### シナリオ

個人開発

個人開発

チーム開発

### 使用例

デフォルトでは、MLflowは各実行のメタデータとアーティファクトをローカルディレクトリmlrunsに記録します。これは、外部サーバ、データベース、ストレージを設定せずにMLflow Tracking を始める最も簡単な方法です。

MLflowクライアントは、バックエンドとしてSQLAlchemy互換データベース（例：SQLite、PostgreSQL、MySQL）とインターフェイスを取ることができます。メタデータをデータベースに保存することで、サーバの設定労力を省きつつ、実験データの管理がよりクリーンになります。

MLflow Tracking サーバは、アーティファクトHTTPプロキシとともに設定することができ、アーティファクトリクエストをトラッキングサーバを通じて送受信することで、基盤となるオブジェクトストアサービスとの直接的なやり取りなしにアーティファクトを保存・取得します。これは、アーティファクトや実験メタデータを適切なアクセス制御を持つ共有場所に保存したいチーム開発シナリオに特に有用です。

### チュートリアル

クイックスタート

ローカルデータベースを使用した実験のトラッキング

MLflow Tracking サーバを使用したリモート実験トラッキング


<!--
### Other Configuration with MLflow Tracking Server

MLflow Tracking Server provides customizability for other special use cases. Please follow Remote Experiment Tracking with MLflow Tracking Server for learning the basic setup and continue to the following materials for advanced configurations to meet your needs.

#### Using MLflow Tracking Server Locally

You can of course run MLflow Tracking Server locally. While this doesn't provide much additional benefit over directly using the local files or database, might useful for testing your team development workflow locally or running your machine learning code on a container environment.

![](https://mlflow.org/docs/latest/_static/images/tracking/tracking-setup-local-server.png)

#### Running MLflow Tracking Server in Artifacts-only Mode

MLflow Tracking Server has `--artifacts-only` option, which lets the server to serve (proxy) only artifacts and not metadata. This is particularly useful when you are in a large organization or training huge models, you might have high artifact transfer volumes and want to split out the traffic for serving artifacts to not impact tracking functionality. Please read Optionally using a Tracking Server instance exclusively for artifact handling for more details on how to use this mode.

![](https://mlflow.org/docs/latest/_static/images/tracking/tracking-setup-artifacts-only.png)



#### Disable Artifact Proxying to Allow Direct Access to Artifacts

MLflow Tracking Server, by default, serves both artifacts and only metadata. However, in some cases, you may want to allow direct access to the remote artifacts storage to avoid the overhead of a proxy while preserving the functionality of metadata tracking. This can be done by disabling artifact proxying by starting server with `--no-serve-artifacts` option. Refer to Use Tracking Server without Proxying Artifacts Access for how to set this up.

![](https://mlflow.org/docs/latest/_static/images/tracking/tracking-setup-no-serve-artifacts.png)
-->

### MLflow Tracking サーバのその他の設定

MLflow Tracking サーバは、特別な使用例に対してもカスタマイズ可能です。基本的な設定を学ぶために「MLflow Tracking サーバを使用したリモート実験トラッキング」を参照し、その後、ニーズに合った高度な設定について学ぶための以下の資料を続けてください。

#### ローカルでのMLflow Tracking サーバの使用

もちろん、MLflow Tracking サーバをローカルで実行することもできます。これにはローカルファイルやデータベースを直接使用する場合と比べて大きな追加利益はありませんが、チーム開発ワークフローをローカルでテストする場合や、コンテナ環境で機械学習コードを実行する場合に役立つかもしれません。

![](https://mlflow.org/docs/latest/_static/images/tracking/tracking-setup-local-server.png)

#### アーティファクトのみモードでのMLflow Tracking サーバの実行

MLflow Tracking サーバには、サーバがメタデータではなくアーティファクトのみを提供（プロキシ）する`--artifacts-only`オプションがあります。これは、大規模な組織に属している場合や巨大なモデルを学習している場合に特に役立ちます。高いアーティファクト転送量が発生し、トラッキング機能に影響を与えないようにアーティファクト提供のトラフィックを分離したい場合に便利です。このモードの使用方法については、「アーティファクト処理専用のトラッキングサーバインスタンスをオプションで使用する」を参照してください。

![](https://mlflow.org/docs/latest/_static/images/tracking/tracking-setup-artifacts-only.png)

#### アーティファクトプロキシを無効にしてアーティファクトへの直接アクセスを許可

MLflow Tracking サーバはデフォルトでアーティファクトとメタデータの両方を提供します。しかし、場合によっては、プロキシのオーバーヘッドを避けつつメタデータトラッキングの機能を維持するために、リモートアーティファクトストレージへの直接アクセスを許可したい場合があります。これは、`--no-serve-artifacts`オプションでサーバを起動することで、アーティファクトプロキシを無効にすることで実現できます。この設定方法については、「プロキシなしでトラッキングサーバを使用する」を参照してください。

![](https://mlflow.org/docs/latest/_static/images/tracking/tracking-setup-no-serve-artifacts.png)


<!--
## FAQ

### Can I launch multiple runs in parallel?

Yes, MLflow supports launching multiple runs in parallel e.g. multi processing / threading. See Launching Multiple Runs in One Program for more details.

### How can I organize many MLflow Runs neatly?

MLflow provides a few ways to organize your runs:

* Organize runs into experiments - Experiments are logical containers for your runs. You can create an experiment using the CLI, API, or UI.
* Create child runs - You can create child runs under a single parent run to group them together. For example, you can create a child run for each fold in a cross-validation experiment.
* Add tags to runs - You can associate arbitrary tags with each run, which allows you to filter and search runs based on tags.

### Can I directly access remote storage without running the Tracking Server?

Yes, while it is best practice to have the MLflow Tracking Server as a proxy for artifacts access for team development workflows, you may not need that if you are using it for personal projects or testing. You can achieve this by following the workaround below:

1. Set up artifacts configuration such as credentials and endpoints, just like you would for the MLflow Tracking Server. See configure artifact storage for more details.
2. Create an experiment with an explicit artifact location,
-->

## よくある質問 (FAQ)

### 複数の実行を並行して起動できますか？

はい、MLflowは複数の実行を並行して起動することをサポートしています。例えば、マルチプロセスやスレッドを使用します。詳細については「一つのプログラムで複数の実行を起動する」を参照してください。

### 多くのMLflow実行を整然と整理するにはどうすればいいですか？

MLflowは実行を整理するいくつかの方法を提供しています：

* 実験に実行を整理する - 実験は実行のための論理的なコンテナです。CLI、API、またはUIを使用して実験を作成できます。
* 子実行を作成する - 一つの親実行の下に子実行を作成してグループ化することができます。例えば、クロスバリデーション実験の各フォールドに対して子実行を作成することができます。
* 実行にタグを追加する - 各実行に任意のタグを関連付けることができ、これによりタグに基づいて実行をフィルタリングして検索することができます。

### トラッキングサーバを使用せずにリモートストレージに直接アクセスできますか？

はい、チーム開発のワークフローにおいてMLflow Tracking サーバをアーティファクトアクセスのプロキシとして使用することがベストプラクティスですが、個人プロジェクトやテスト用途で使用している場合はそれが必要ないかもしれません。以下のワークアラウンドに従うことでこれを実現できます：

1. MLflow Tracking サーバで行うように、アーティファクト設定（認証情報やエンドポイントなど）を設定します。詳細については、アーティファクトストレージの設定を参照してください。
2. 明示的なアーティファクトロケーションを持つ実験を作成します。


```python
experiment_name = "your_experiment_name"
mlflow.create_experiment(experiment_name, artifact_location="s3://your-bucket")
mlflow.set_experiment(experiment_name)
```

<!--
Your runs under this experiment will log artifacts to the remote storage directly.

### How to integrate MLflow Tracking with Model Registry?

To use the Model Registry functionality with MLflow tracking, you must use database backed store such as PostgresQL and log a model using the log_model methods of the corresponding model flavors. Once a model has been logged, you can add, modify, update, or delete the model in the Model Registry through the UI or the API. See Backend Stores and Common Setups for how to configures backend store properly for your workflow.

### How to include additional decription texts about the run?

A system tag `mlflow.note.content` can be used to add descriptive note about this run. While the other system tags are set automatically, this tag is not set by default and users can override it to include additional information about the run. The content will be displayed on the run’s page under the Notes section.
-->

実験の下で実行される実行は、アーティファクトを直接リモートストレージにログします。

### MLflow Tracking をモデルレジストリと統合する方法は？

MLflow Tracking とモデルレジストリ機能を使用するには、PostgreSQLなどのデータベースバックエンドストアを使用し、対応するモデルフレーバーのlog_modelメソッドを使用してモデルをログする必要があります。モデルがログされると、UIまたはAPIを通じてモデルレジストリ内でモデルを追加、修正、更新、削除できます。ワークフローに適切にバックエンドストアを設定する方法については、バックエンドストアと一般的なセットアップを参照してください。

### 実行についての追加の説明テキストを含める方法は？

システムタグ `mlflow.note.content` を使用して、この実行についての説明的なメモを追加できます。他のシステムタグは自動的に設定されるのに対し、このタグはデフォルトで設定されておらず、ユーザーは実行に関する追加情報を含めるためにこれを上書きすることができます。内容は実行のページのノートセクションに表示されます。

