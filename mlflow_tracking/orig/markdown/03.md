<!--
# 5 Minute Tracking Server Overview

* [https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html](https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)

In this guide we will walk you through how to view your MLflow experiment results with different types of tracking server configurations. At a high level, there are 3 ways to view your MLflow experiments:

* [Method 1] Start your own MLflow server.
* [Method 2] Use a free hosted tracking server - Databricks Community Edition.
* [Method 3] Use production Databricks/AzureML.

To choose among these 3 methods, here is our recommendation:

* If you have privacy concerns (data/model/tech stack), use Method 1 - start your own server.
* If you are a student or an individual researcher, or if you are developing in cloud-based notebooks (e.g., Google Colab), use Method 2 - free hosted tracking server.
* Enterprise users, or if you want to serve or deploy your model for a production use-case, please use Method 3 - production Databricks/AzureML.

Overall Method 2 - free hosted tracking server is the simplest way to get started with MLflow, but please pick the method that best suits your needs.
-->

# 5分間のトラッキングサーバー概要

* [https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html](https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)

このガイドでは、異なるタイプのトラッキングサーバー構成でMLflow実験結果を表示する方法を説明します。概要として、MLflow実験を表示する方法は3つあります：

* [方法 1] 自分のMLflowサーバーを起動します。
* [方法 2] 無料のホスト型トラッキングサーバー - Databricks Community Editionを使用します。
* [方法 3] 本番用のDatabricks/AzureMLを使用します。

これら3つの方法の中から選択するために、ここでは私たちの推奨を示します：

### 方法1: 自分自身のMLflowサーバーを開始する

**最適なユーザー**: プライバシーに関する懸念があるユーザーや、データ、モデル、技術スタックを完全にコントロールしたいユーザー。

**実施方法**: 自分自身でMLflowトラッキングサーバーを設定し管理します。これには、自分のサーバーまたはローカルマシンにMLflowをインストールし、環境を設定し、自分の条件に合わせてアクセスとストレージを管理することが含まれます。この方法では完全なコントロールが可能で、特に機密性が高いまたはプライベートなデータ管理に適しています。

**実装手順**:
1. 選択したサーバーにMLflowをインストールする。
2. データのプライバシーとアクセスニーズに合わせてサーバー設定を構成する。
3. サーバーを起動し、実験のトラッキングを開始する。

### 方法2: 無料のホスト型トラッキングサーバーを使用する - Databricks Community Edition

**最適なユーザー**: 学生、個人研究者、またはGoogle Colabのようなクラウドベースのノートブックを使用する開発者で、プライベートサーバーの堅牢性が必要ない人。

**実施方法**: Databricksの無料ホスト版を利用してMLflow実験を管理・閲覧します。このオプションはクラウドベースで、ローカルインストールの必要なくどこからでもアクセス可能です。

**実装手順**:
1. Databricks Community Editionの無料アカウントにサインアップする。
2. MLflow実験をこのサーバーにトラッキングするように設定する。
3. Databricksのインターフェースを通じて実験にアクセスする。

### 方法3: 本番環境用のDatabricks/AzureMLを使用する

**最適なユーザー**: 企業ユーザーやモデルを本番環境で使用・展開したい人。

**実施方法**: DatabricksやAzureMLの商用サービスを使用します。これは、さまざまなデータソースやMLツールとの高いスケーラビリティと統合を目的として設計されています。

**実装手順**:
1. 事業のニーズに合った適切なDatabricksまたはAzureMLプランを選択する。
2. サービスのガイドラインに従ってトラッキングサーバーを設定する。
3. 強化されたセキュリティ、協働ツール、本番レベルの機能を備えてMLflow実験のトラッキングを開始する。

### 正しい方法の選択

- **プライバシーに関する懸念がある場合**: データやモデルが制御された環境内に留まることを保証するためには、**方法1**が最適です。
- **使いやすさとアクセシビリティ**: 設定の手間なく簡単にアクセスしたい場合は、**方法2**が最良の選択です。
- **スケーラビリティと本番環境のニーズ**: 企業や本番環境での運用を考えている場合、さまざまなクラウドサービスとの統合が求められる**方法3**が適しています。


<!--
## Method 1: Start Your Own MLflow Server

Disclaimier: This part of guide is not suitable for running in a cloud-provided IPython environment (e.g., Collab, Databricks). Please follow the guide below in your local machine (laptop/desktop).

A hosted tracking server is the simplest way to store and view MLflow experiments, but it is not suitable for every user. For example, you may not want to expose your data and model to others in your cloud provider account. In this case, you can use a local hosted MLflow server to store and view your experiments. To do so, there are two steps:

* Start your MLflow server.
* Connect MLflow session to the local MLflow server IP by mlflow.set_tracking_uri().

### Start a Local MLflow Server

If you don’t have MLflow installed, please run the command below to install it:
-->

## 方法 1: 自分のMLflowサーバーを起動する

免責事項: このガイドのこの部分は、クラウド提供のIPython環境（例：Collab、Databricks）で実行するのに適していません。以下のガイドに従って、ローカルマシン（ノートパソコン/デスクトップ）で実行してください。

ホスト型トラッキングサーバーは、MLflow実験を保存して閲覧する最もシンプルな方法ですが、すべてのユーザーに適しているわけではありません。例えば、クラウドプロバイダーのアカウントで他の人にデータやモデルを公開したくない場合があります。この場合、ローカルホスト型MLflowサーバーを使用して実験を保存して閲覧することができます。これを行うには、以下の二つのステップがあります：

* MLflowサーバーを起動します。
* `mlflow.set_tracking_uri()` を使用してMLflowセッションをローカルMLflowサーバーIPに接続します。

### ローカルMLflowサーバーを起動する

まだMLflowがインストールされていない場合は、以下のコマンドを実行してインストールしてください：


```bash
$ pip install mlflow
```

<!--
The installation of MLflow includes the MLflow CLI tool, so you can start a local MLflow server with UI by running the command below in your terminal:
-->
MLflowのインストールにはMLflow CLIツールが含まれているため、以下のコマンドをターミナルで実行することで、UI付きのローカルMLflowサーバーを起動することができます：

```bash
$ mlflow ui
```
<!--
It will generate logs with the IP address, for example:
-->
例えば、IPアドレスでログを生成する：

```
(mlflow) [master][~/Documents/mlflow_team/mlflow]$ mlflow ui
[2023-10-25 19:39:12 -0700] [50239] [INFO] Starting gunicorn 20.1.0
[2023-10-25 19:39:12 -0700] [50239] [INFO] Listening at: http://127.0.0.1:5000 (50239)
```

<!--
Opening the URL of the MLflow tracking server in your browser will bring you to the MLflow UI. The image below is from the open source version of the MLflow UI, which is a bit different from the MLflow UI on Databricks CE. Below is a screenshot of the landing page:

![Landing page of OSS MLflow server](https://mlflow.org/docs/latest/_images/mlflow-localhost-landing-page.png)

Note

It’s also possible to deploy your own MLflow server on cloud platforms, but it is out of the scope of this guide.

### Connect MLflow Session to Your Server

Now that the server is spun up, let’s connect our MLflow session to the local server. This is very similar to how we connect to a remote hosted tracking provider such as the Databricks platform.
-->

ブラウザでMLflowトラッキングサーバーのURLを開くと、MLflow UIにアクセスできます。以下の画像はオープンソース版のMLflow UIからのもので、Databricks CEのMLflow UIとは少し異なります。以下はランディングページのスクリーンショットです：

![OSS MLflowサーバーのランディングページ](https://mlflow.org/docs/latest/_images/mlflow-localhost-landing-page.png)

注記

自分のMLflowサーバーをクラウドプラットフォームにデプロイすることも可能ですが、それはこのガイドの範囲外です。

### MLflowセッションをサーバーに接続する

サーバーが稼働したので、ローカルサーバーにMLflowセッションを接続しましょう。これはDatabricksプラットフォームなどのリモートホスト型トラッキングプロバイダーに接続する方法と非常に似ています。

```python
mlflow.set_tracking_uri("http://localhost:5000")
```

<!--
Next, let’s try logging some dummy metrics. We can view these test metrics on the local hosted UI:
-->
次に、いくつかのダミーメトリクスをログに記録してみましょう。これらのテストメトリクスはローカルホストされたUIで確認することができます：


```python
mlflow.set_experiment("/check-localhost-connection")

with mlflow.start_run():
    mlflow.log_metric("foo", 1)
    mlflow.log_metric("bar", 2)
```

<!--
Putting it together you can copy the following code to your editor and save it as log_mlflow_with_localhost.py:
-->
以下のコードをエディタにコピーして、`log_mlflow_with_localhost.py`として保存してください：


```python
import mlflow

mlflow.set_tracking_uri("http://localhost:5000")
mlflow.set_experiment("check-localhost-connection")

with mlflow.start_run():
    mlflow.log_metric("foo", 1)
    mlflow.log_metric("bar", 2)
```

<!--
Then execute it by:
-->
次に、以下のコマンドを使用して実行します：


```bash
$ python log_mlflow_with_localhost.py
```

<!--
### View Experiment on Your MLflow Server

Now let’s view your experiment on the local server. Open the URL in your browser, which is http://localhost:5000 in our case. In the UI, inside the left sidebar you should see the experiment with name “check-localhost-connection”. Clicking on this experiment name should bring you to the experiment view, similar to what is shown below.

![Experiment view of OSS MLflow server](https://mlflow.org/docs/latest/_images/mlflow-localhost-experiment-view.png)

Clicking on the run (“clumsy-steed-426” in this example, yours will be different) will bring you to the run view, similar as below.

![Run view of OSS MLflow server](https://mlflow.org/docs/latest/_images/mlflow-localhost-run-view.png)

### Conclusion

That’s all about how to start your own MLflow server and view your experiments. Please see the pros and cons of this method below:

* Pros
  * You have full control of your data and model, which is good for privacy concerns.
  * No subscription is required.
  * Unlimited quota of experiments/runs.
  * You can even customize your UI by forking the MLflow repo and modify the UI code.
* Cons
  * Requires manual setup and maintenance.
  * Team collaboration is harder than using a hosted tracking server.
  * Not suitable for cloud-based notebook, e.g., Google Colab.
  * Requires extra port forwarding if you deploy your server on cloud VM.
  * No serving support.
-->

### MLflowサーバーで実験を見る

さて、ローカルサーバーで実験を見てみましょう。ブラウザでURLを開きます。このケースでは `http://localhost:5000` です。UI内の左サイドバーで、「check-localhost-connection」という名前の実験が表示されるはずです。この実験名をクリックすると、以下に示すような実験ビューに移動します。

![OSS MLflowサーバーの実験ビュー](https://mlflow.org/docs/latest/_images/mlflow-localhost-experiment-view.png)

ラン（この例では「clumsy-steed-426」、あなたのものは異なります）をクリックすると、以下のようなランビューに移動します。

![OSS MLflowサーバーのランビュー](https://mlflow.org/docs/latest/_images/mlflow-localhost-run-view.png)

### 結論

これで、自分のMLflowサーバーを起動し、実験を見る方法についての説明はすべてです。この方法の長所と短所を以下に示します：

* 長所
  * データとモデルを完全に制御できるため、プライバシーに関する懸念に適しています。
  * サブスクリプションは必要ありません。
  * 実験/ランの無制限のクォータ。
  * MLflowのリポジトリをフォークしてUIコードを変更することで、UIをカスタマイズすることもできます。
* 短所
  * 手動でのセットアップとメンテナンスが必要です。
  * ホスト型トラッキングサーバーを使用する場合に比べてチームでのコラボレーションが難しい。
  * クラウドベースのノートブック（例：Google Colab）には適していません。
  * クラウドVMにサーバーをデプロイする場合、追加のポートフォワーディングが必要です。
  * サービングサポートがありません。


## Method 2: Use Free Hosted Tracking Server (Databricks Community Edition)

Notice: This part of guide can be directly executed in cloud-based notebook, e.g., Google Colab or Databricks Notebook.

Databricks Community Edition (CE) is the free, limited-use version of the cloud-based big data platform Databricks. Databricks CE users can access a micro-cluster as well as a cluster manager and notebook environment. All users can share their notebooks and host them free of charge with Databricks. You can use Databricks CE to store and view your MLflow experiments without being charged.

To use Databricks CE to store and view our MLflow experiments, basically we need to:

Create a free Databricks CE account.

Set up Databricks CE authentication in our dev environment.

Connect to Databricks CE in our MLflow experiment session.

Then the experiment results will be automatically sent to Databricks CE, where you can view it in MLflow experiment UI. Now let’s look at the code.

### Create a Databricks CE Account

If you don’t have an account of Databricks CE yet, you can create one here. The full process should take no longer than 3 minutes.

### Install Dependencies

```python
%pip install -q mlflow databricks-sdk
```

### Set Up Authentication of Databricks CE

To set up Databricks CE authentication, we can use the API [`mlflow.login()`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.login), which will prompt you for required information:

* Databricks Host: Use [https://community.cloud.databricks.com/](https://community.cloud.databricks.com/)
* Username: Your email address that signs in Databricks CE.
* Password: Your password of Databricks CE.

If the authentication succeeds, you should see a message “Succesfully signed in Databricks!”.

```python
import mlflow

mlflow.login()
```

```
2023/10/25 22:59:27 ERROR mlflow.utils.credentials: Failed to sign in Databricks: default auth: cannot configure default credentials
Databricks Host (should begin with https://): https://community.cloud.databricks.com/
Username: weirdmouse@gmail.com
Password: ··········
2023/10/25 22:59:38 INFO mlflow.utils.credentials: Succesfully signed in Databricks!
```

### Connect MLflow Session to Databricks CE

We have set up the credentials, now we need to tell MLflow to send the data into Databricks CE. To do so, we will use mlflow.set_tracking_uri("databricks") to port MLflow to Databricks CE. Basically it is the command below. Please note that you need to always use “databricks” as the keyword.

```python
mlflow.set_tracking_uri("databricks")
```

Now you are ready to go! Let’s try starting an MLflow experiment and log some dummy metrics and view it in our UI.

```python
mlflow.set_experiment("/check-databricks-connection")

with mlflow.start_run():
    mlflow.log_metric("foo", 1)
    mlflow.log_metric("bar", 2)
```


```
2023/10/25 23:15:42 INFO mlflow.tracking.fluent: Experiment with name '/check-databricks-ce-connection' does not exist. Creating a new experiment.
```

### View Your Experiment on Databricks CE

Now let’s navigate to Databricks CE to view the experiment result. Log in to your Databricks CE account, and click on top left to select machine learning in the drop down list. Then click on the experiment icon. See the screenshot below:

![Landing page of Databricks MLflow server](https://mlflow.org/docs/latest/_images/databricks-ce-landing-page.png)
In the “Experiments” view, you should be able to find the experiment “/check-databricks-ce-connection”, similar to

![Experiment view of Databricks MLflow server](https://mlflow.org/docs/latest/_images/databricks-ce-experiment-view.png)

Clicking on the run name, in our example it is “youthful-lamb-287” (it’s a randomly generated name, you will see a different name in your CE console), will bring you to the run view, similar to

![Experiment view of Databricks MLflow server](https://mlflow.org/docs/latest/_images/databricks-ce-run-view.png)

In the run view, you will see our dummy metrics “foo” and “bar” are logged successfully.

### Conclusion

That’s all about how to use Databricks CE as the tracking server. Please see the pros and cons of this method below:

* Pros
  * Effortless setup.
  * Free.
  * Good for collaboration, e.g., you can share your MLflow experiment with your teammates easily.
  * Compatible for developing on cloud-based notebook, e.g., Google Colab.
  * Compatible for developing on cloud VM.
* Cons
  * Has quota limit of experiments/runs.
  * No model registration/serving support.

<!--
## Method 3: Use Production Hosted Tracking Server

If you are an enterprise user and willing to productionize your model, you can use a production platform like Databricks or Microsoft AzureML. If you use Databricks, MLflow experiment will log your model into the Databricks MLflow server, and you can register your model then serve your model by a few clicks. Serving feature is only available on production Databricks workspace, and not available on Databricks CE.

The method of using production Databricks is the same as using Databricks CE, you only need to change the host to be the production workspace. For example, `https://dbc-1234567-123.cloud.databricks.com`. For more information about how Databricks power your Machine Learning workflow, please refer to the doc here.

To use AzureML as the tracking server, please read the doc here

### Conclusion

That’s all about how to use a production platform as the tracking server. Please see the pros and cons of this method below:

* Pros
  * Effortless setup.
  * Good for collaboration, e.g., you can share your MLflow experiment with your teammates easily.
  * Compatible for developing on cloud-based notebook, e.g., Google Colab.
  * Compatible for developing on cloud VM.
  * Seamless model registration/serving support.
  * Higher quota than Databricks CE (pay as you go).
* Cons
  * Not free.
  * Need to manage a billing account.
-->

## 方法 3: 本番ホスト型トラッキングサーバーの使用

企業ユーザーでモデルを本番化したい場合、DatabricksやMicrosoft AzureMLのような本番プラットフォームを使用できます。Databricksを使用すると、MLflow実験はモデルをDatabricksのMLflowサーバーにログし、数回クリックするだけでモデルを登録して提供することができます。提供機能は本番Databricksワークスペースでのみ利用可能であり、Databricks CEでは利用できません。

本番Databricksを使用する方法はDatabricks CEを使用する方法と同じで、ホストを本番ワークスペースに変更するだけです。例えば、`https://dbc-1234567-123.cloud.databricks.com`です。Databricksがどのようにしてあなたの機械学習ワークフローを強化するかについての詳細は、こちらのドキュメントを参照してください。

AzureMLをトラッキングサーバーとして使用するには、こちらのドキュメントをお読みください。

### 結論

これで、トラッキングサーバーとして本番プラットフォームを使用する方法についてすべて説明しました。この方法の長所と短所を以下に示します：

* 長所
  * セットアップが容易です。
  * コラボレーションに適しています。例えば、MLflow実験をチームメイトと簡単に共有できます。
  * クラウドベースのノートブックでの開発に対応しています。例：Google Colab。
  * クラウドVMでの開発に対応しています。
  * モデル登録/提供のサポートがシームレスです。
  * Databricks CEよりも高いクォータ（利用した分だけ支払い）。
* 短所
  * 無料ではありません。
  * 請求アカウントの管理が必要です。


