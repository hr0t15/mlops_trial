<!--
# MLflow Tracking Quickstart

* [https://mlflow.org/docs/latest/getting-started/intro-quickstart/index.html](https://mlflow.org/docs/latest/getting-started/intro-quickstart/index.html)

Welcome to MLflow!

The purpose of this quickstart is to provide a quick guide to the most essential core APIs of MLflow Tracking. Specifically, those that enable the logging, registering, and loading of a model for inference.

Note

For a more in-depth and tutorial-based approach (if that is your style), please see the Getting Started with MLflow tutorial. We recommend that you start here first, though, as this quickstart uses the most common and frequently-used APIs for MLflow Tracking and serves as a good foundation for the other tutorials in the documentation.

## What you will learn

In just a few minutes of following along with this quickstart, you will learn:

* How to log parameters, metrics, and a model
* The basics of the MLflow fluent API
* How to register a model during logging
* How to navigate to a model in the MLflow UI
* How to load a logged model for inference

If you would like to see this quickstart in a purely notebook format, we have a downloadable and viewable notebook-only version of this quickstart:

[View the Notebook](https://mlflow.org/docs/latest/getting-started/intro-quickstart/notebooks/index.html)
-->

# MLflow Tracking入門

* [MLflow 入門ガイド](https://mlflow.org/docs/latest/getting-started/intro-quickstart/index.html)

MLflowへようこそ！

この入門ガイドの目的は、MLflow Trackingの最も重要なコアAPIを迅速に紹介することです。具体的には、モデルを記録、登録、および推論用にロードする機能を有効にするAPIです。

**注意**

より深い内容とチュートリアル形式のアプローチがお好みであれば、「MLflow入門」チュートリアルをご覧ください。ただし、この入門ガイドではMLflow Trackingで最も一般的で頻繁に使用されるAPIを取り扱っているため、他のチュートリアルに進むための良い基盤となりますので、まずこちらから始めることをお勧めします。

## 学べること

この入門ガイドに沿って数分間学習するだけで、以下のことがわかるようになります：

- パラメータ、メトリック、モデルのログ方法
- MLflow fluent APIの基本
- ログ中にモデルを登録する方法
- MLflow UIでモデルにナビゲートする方法
- ログしたモデルを推論用にロードする方法

この入門ガイドを純粋なノートブック形式で見たい場合、ダウンロード可能で閲覧可能なノートブックのみのバージョンも用意しています：

[ノートブックを見る](https://mlflow.org/docs/latest/getting-started/intro-quickstart/notebooks/index.html)

<!--
## Step 1 - Get MLflow

MLflow is available on PyPI. If you don’t already have it installed on your system, you can install it with:

```Bash
pip install mlflow
```
-->

## ステップ1 - MLflowの取得

MLflowはPyPIで利用可能です。もしまだシステムにインストールされていない場合、以下のコマンドでインストールできます：

```Bash
pip install mlflow
```

<!--
## Step 2 - Start a Tracking Server

Using a Managed MLflow Tracking Server
For details on options for using a managed MLflow Tracking Server, including how to create a free Databricks Community Edition account with managed MLflow, [see the guide for tracking server options](https://mlflow.org/docs/latest/getting-started/running-notebooks/index.html).
-->

## ステップ2 - Tracking サーバの起動

マネージドMLflowTracking サーバを使用する
マネージドMLflowTracking サーバの使用オプションについて、無料のDatabricks Community EditionアカウントでマネージドMLflowを作成する方法を含む詳細情報は、[Tracking サーバのオプションに関するガイドを参照してください](https://mlflow.org/docs/latest/getting-started/running-notebooks/index.html)。

<!--
## (Optional) Run a local Tracking Server

We’re going to start a local MLflow Tracking Server, which we will connect to for logging our data for this quickstart. From a terminal, run:

```Bash
mlflow server --host 127.0.0.1 --port 8080
```

Note

You can choose any port that you would like, provided that it’s not already in use.

Set the Tracking Server URI (if not using a Databricks Managed MLflow Tracking Server)
If you’re using a managed MLflow Tracking Server that is not provided by Databricks, or if you’re running a local tracking server, ensure that you set the tracking server’s uri using:
-->

## （オプション）ローカルTracking サーバの実行

この入門ガイドのために、ローカルのMLflowTracking サーバを起動し、そこにデータをログする接続を行います。ターミナルから以下のコマンドを実行してください：

```Bash
mlflow server --host 127.0.0.1 --port 8080
```

**注意**

好きなポートを選んでください。ただし、そのポートが既に使用されていないことを確認してください。

Tracking サーバURIの設定（DatabricksマネージドMLflow Tracking サーバを使用しない場合）
Databricksによって提供されていないマネージドMLflow Tracking サーバを使用している場合、またはローカルのTracking サーバを実行している場合、以下を使用してTracking サーバのURIを設定してください：

```Python
import mlflow

mlflow.set_tracking_uri(uri="http://<host>:<port>")
```

<!--
If this is not set within your notebook or runtime environment, the runs will be logged to your local file system.
-->
設定されていない場合、実行はローカルファイルシステムにログされます。

<!--
## Step 3 - Train a model and prepare metadata for logging

In this section, we’re going to log a model with MLflow. A quick overview of the steps are:

* Load and prepare the Iris dataset for modeling.
* Train a Logistic Regression model and evaluate its performance.
* Prepare the model hyperparameters and calculate metrics for logging.
-->


## ステップ3 - モデルの学習とログ用メタデータの準備

このセクションでは、MLflowを使用してモデルをログします。手順の概要は以下の通りです：

* アイリスデータセットを読み込み、モデリングのために準備します。
* ロジスティック回帰モデルを学習し、そのパフォーマンスを評価します。
* モデルのハイパーパラメータを準備し、ログするためのメトリックを計算します。

```Python
import mlflow
from mlflow.models import infer_signature

import pandas as pd
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score


# Load the Iris dataset
X, y = datasets.load_iris(return_X_y=True)

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Define the model hyperparameters
params = {
    "solver": "lbfgs",
    "max_iter": 1000,
    "multi_class": "auto",
    "random_state": 8888,
}

# Train the model
lr = LogisticRegression(**params)
lr.fit(X_train, y_train)

# Predict on the test set
y_pred = lr.predict(X_test)

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred)
```

<!--
## Step 4 - Log the model and its metadata to MLflow

In this next step, we’re going to use the model that we trained, the hyperparameters that we specified for the model’s fit, and the loss metrics that were calculated by evaluating the model’s performance on the test data to log to MLflow.

The steps that we will take are:

* Initiate an MLflow run context to start a new run that we will log the model and metadata to.
* Log model parameters and performance metrics.
* Tag the run for easy retrieval.
* Register the model in the MLflow Model Registry while logging (saving) the model.

Note

While it can be valid to wrap the entire code within the start_run block, this is not recommended. If there as in issue with the training of the model or any other portion of code that is unrelated to MLflow-related actions, an empty or partially-logged run will be created, which will necessitate manual cleanup of the invalid run. It is best to keep the training execution outside of the run context block to ensure that the loggable content (parameters, metrics, artifacts, and the model) are fully materialized prior to logging.
-->

## ステップ4 - MLflowにモデルとそのメタデータをログする

次のステップでは、学習したモデル、モデルのフィットに指定したハイパーパラメータ、およびテストデータでのモデルのパフォーマンスを評価することで計算された損失メトリックを使用してMLflowにログします。

取るべき手順は以下の通りです：

* MLflowの実行コンテキストを開始し、新しい実行を開始してモデルとメタデータをログします。
* モデルパラメータとパフォーマンスメトリックをログします。
* 容易な検索のために実行をタグ付けします。
* モデルをログ（保存）する際に、MLflowモデルレジストリに登録します。

注意

全てのコードを`start_run`ブロック内に包含することも有効ですが、これは推奨されません。モデルの学習やMLflow関連のアクションと無関係なその他のコード部分に問題があった場合、空の実行または部分的にログされた実行が作成される可能性があり、無効な実行の手動でのクリーンアップが必要になることがあります。学習の実行を実行コンテキストブロックの外に保持することが最善であり、ログ可能な内容（パラメータ、メトリック、アーティファクト、モデル）がログ記録前に完全に具現化されることを保証します。

```Python
# Set our tracking server uri for logging
mlflow.set_tracking_uri(uri="http://127.0.0.1:8080")

# Create a new MLflow Experiment
mlflow.set_experiment("MLflow Quickstart")

# Start an MLflow run
with mlflow.start_run():
    # Log the hyperparameters
    mlflow.log_params(params)

    # Log the loss metric
    mlflow.log_metric("accuracy", accuracy)

    # Set a tag that we can use to remind ourselves what this run was for
    mlflow.set_tag("Training Info", "Basic LR model for iris data")

    # Infer the model signature
    signature = infer_signature(X_train, lr.predict(X_train))

    # Log the model
    model_info = mlflow.sklearn.log_model(
        sk_model=lr,
        artifact_path="iris_model",
        signature=signature,
        input_example=X_train,
        registered_model_name="tracking-quickstart",
    )
```

<!--
## Step 5 - Load the model as a Python Function (pyfunc) and use it for inference

After logging the model, we can perform inference by:

* Loading the model using MLflow’s pyfunc flavor.
* Running Predict on new data using the loaded model.

Note

The iris training data that we used was a numpy array structure. However, we can submit a Pandas DataFrame as well to the predict method, as shown below.
-->

## ステップ5 - モデルをPython関数（pyfunc）としてロードし、推論に使用する

モデルをログした後、以下の方法で推論を行うことができます：

* MLflowの`pyfunc`フレーバーを使用してモデルをロードします。
* ロードしたモデルを使用して新しいデータに対する予測を実行します。

注意

使用したアイリス学習データはnumpy配列の構造でした。しかし、以下に示すように、予測メソッドにPandas DataFrameも提出できます。


```Python
# Load the model back for predictions as a generic Python Function model
loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)

predictions = loaded_model.predict(X_test)

iris_feature_names = datasets.load_iris().feature_names

result = pd.DataFrame(X_test, columns=iris_feature_names)
result["actual_class"] = y_test
result["predicted_class"] = predictions

result[:4]
```

The output of this code will look something like this:

sepal length (cm)

sepal width (cm)

petal length (cm)

petal width (cm)

actual_class

predicted_class

6.1

2.8

4.7

1.2

1

1

5.7

3.8

1.7

0.3

0

0

7.7

2.6

6.9

2.3

2

2

6.0

2.9

4.5

1.5

1

1

<!--
## Step 6 - View the Run in the MLflow UI

In order to see the results of our run, we can navigate to the MLflow UI. Since we have already started the Tracking Server at [http://localhost:8080](http://localhost:8080), we can simply navigate to that URL in our browser.

When opening the site, you will see a screen similar to the following:

![MLflow UI Experiment view page](https://mlflow.org/docs/latest/_images/quickstart-our-experiment.png)

The main MLflow Tracking page, showing Experiments that have been created
Clicking on the name of the Experiment that we created (“MLflow Quickstart”) will give us a list of runs associated with the Experiment. You should see a random name that has been generated for the run and nothing else show up in the Table list view to the right.

Clicking on the name of the run will take you to the Run page, where the details of what we’ve logged will be shown. The elements have been highlighted below to show how and where this data is recorded within the UI.

![MLflow UI Run view page](https://mlflow.org/docs/latest/_images/quickstart-our-run.png)

The run view page for our run
-->

## ステップ6 - MLflow UIで実行を確認する

実行の結果を確認するために、MLflow UIにアクセスします。既に [http://localhost:8080](http://localhost:8080) でTracking サーバを開始しているため、ブラウザでそのURLにナビゲートするだけです。

サイトを開くと、以下のような画面が表示されます：

![MLflow UI実験ビューページ](https://mlflow.org/docs/latest/_images/quickstart-our-experiment.png)

作成された実験を示す主なMLflow Trackingページ
作成した実験（「MLflowクイックスタート」）の名前をクリックすると、その実験に関連付けられた実行のリストが表示されます。テーブルリストビューの右側には、ランダムに生成された実行名のみが表示されます。

実行の名前をクリックすると、ログした内容の詳細が表示される実行ページに移動します。UI内でこのデータがどのように記録されているかを示すために、要素が以下のように強調表示されています。

![MLflow UI実行ビューページ](https://mlflow.org/docs/latest/_images/quickstart-our-run.png)

私たちの実行のための実行ビューページ


<!--
## Conclusion

Congratulations on working through the MLflow Tracking Quickstart! You should now have a basic understanding of how to use the MLflow Tracking API to log models.

If you are interested in a more in-depth tutorial, please see the Getting Started with MLflow tutorial as a good next step in increasing your knowledge about MLflow!
-->

## 結論

MLflow Trackingクイックスタートを進めるおめでとうございます！これで、モデルをログするためのMLflow Tracking APIの使用方法の基本を理解することができたはずです。

さらに詳細なチュートリアルに興味がある場合は、「MLflow入門」チュートリアルを次のステップとして参照してください。これはMLflowについての知識を深めるのに良い次のステップです！
